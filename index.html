<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" />

<title>Latent-Variable Modeling and Representation Learning for NLP (NAACL 2015 workshop)</title>
</head>

<body>
    <div id="page">
		
        <div id="header">
        	<h1>Workshop on Latent-Variable Modeling and Representation Learning for NLP</h1>
            <h2>NAACL 2015, Denver, Colorado (June 4 or 5, 2015)</h2>
            
      </div>
        <div id="bar">
            <ul>
                <li><a href="index.html">Overview</a></li>
                <li><a href="cfp.html">Call for Papers</a></li>
                <li><a href="speakers.html">Invited Speakers</a></li>
                <li><a href="org.html">Organization</a></li>
                <li><a href="schedule.html">Schedule and Abstracts</a></li>
                <li><a href="bib.html">Bibliography</a></li>
            </ul>
      </div>
        <div class="contentTitle"><h1>Overview</h1></div>
        <div class="contentText">
NLP started with methods based on pure symbolic analysis of language. Statistical methods were introduced to NLP in the 1990s, allowing "soft" reasoning about language and made it more data-driven. Over the last couple of decades another step has been taken in this direction--it was proposed to represent and analyze language in vector spaces. Now-a-days, context, symbolic and high-dimensional representations are often augmented with relatively low-dimensional vector-space representations. Vector space representations have been shown to be successful in different areas of NLP such as syntax and semantics.
</div>

<br>

        <div class="contentText">
This workshop is an opportunity to explore state-of-the-art regarding the use of vector spaces in order to computationally analyze natural language. The focus of the workshop will be on the use of vector spaces to learn latent-variable representations.
        </div>
<br>

	<div class="contentText">
The goal of the workshop is to bring together researchers from areas such as deep learning and representation learning, spectral learning, distributional compositional semantics and others, in order to see their relevance to each and other, and learn about the state of the art in these areas.
	</div>

<br>

	<div class="contentText">
	For a list of topics this workshop seeks to explore, see the <a href=cfp.html>call for papers</a>.
	</div>

        <div id="footer"><a href="http://www.bryantsmith.com">web page designer </a> <a href="http://www.bryantsmith.com">bryant smith</a></div>
</body>
</html>
